{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f90acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1552a0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0012,  0.0483,  0.0756,  ...,  0.0040,  0.0285, -0.0502],\n",
      "        [ 0.0860, -0.0455,  0.0128,  ...,  0.0526, -0.0257, -0.0346],\n",
      "        [-0.0958, -0.0890,  0.0198,  ...,  0.0476, -0.0044, -0.0526],\n",
      "        ...,\n",
      "        [-0.0936, -0.0026, -0.0254,  ..., -0.0843, -0.0208,  0.0707],\n",
      "        [ 0.0802,  0.0897,  0.0013,  ...,  0.0185, -0.0058,  0.0820],\n",
      "        [ 0.0608,  0.0262, -0.0741,  ...,  0.0627, -0.0404,  0.0934]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-2.3439e-03, -6.8820e-02, -7.6703e-02,  3.2795e-02, -6.0495e-02,\n",
      "         2.0355e-02,  3.4383e-02,  6.5146e-02, -1.5472e-02,  3.0259e-02,\n",
      "        -5.8367e-02, -3.4639e-02, -7.0562e-02, -2.1699e-02,  1.0125e-02,\n",
      "        -6.0008e-03, -8.0510e-02,  8.8132e-02,  5.2131e-02, -9.1257e-02,\n",
      "        -1.9060e-02,  7.2659e-02,  8.8445e-02,  7.7902e-02,  9.9575e-02,\n",
      "         8.5933e-02,  6.9266e-02,  1.4871e-02,  8.8563e-02,  2.0709e-03,\n",
      "         7.7639e-02,  6.7888e-02,  1.5691e-03,  7.9578e-02, -4.9115e-02,\n",
      "         2.3234e-02,  8.6846e-02, -6.8800e-02,  8.2347e-02, -3.4734e-03,\n",
      "         2.9571e-02, -1.4705e-02,  5.0552e-02, -2.5612e-02, -8.3800e-02,\n",
      "         9.7157e-02, -2.4149e-02, -9.4736e-02, -2.1187e-02, -4.6630e-02,\n",
      "         9.9589e-02, -5.9396e-02,  2.8750e-02,  9.6404e-02, -6.4785e-02,\n",
      "        -1.9088e-02, -7.7317e-02,  4.9161e-02, -8.2907e-02,  5.0476e-02,\n",
      "         3.1812e-02,  6.4546e-02, -6.7865e-02,  8.1880e-04, -4.8095e-02,\n",
      "        -9.1810e-02,  1.5588e-02,  1.2672e-02, -4.6175e-02,  7.9324e-03,\n",
      "         9.2092e-02, -6.9915e-02, -1.7423e-02, -8.4509e-02,  2.8885e-02,\n",
      "         8.4666e-02,  1.0658e-02, -2.8400e-02,  4.7636e-02, -9.9793e-02,\n",
      "         1.5543e-02,  9.9820e-02,  8.7965e-02, -2.3116e-02,  4.1927e-02,\n",
      "        -8.8282e-02,  1.3022e-02, -4.4129e-02,  6.2117e-02, -6.6867e-02,\n",
      "        -7.7188e-02,  4.8779e-02, -7.5512e-03,  8.3353e-02, -3.3421e-03,\n",
      "        -6.1113e-02,  5.9749e-02,  6.4481e-02, -2.3644e-02, -7.3782e-02,\n",
      "        -1.6428e-02,  8.7243e-02,  7.9184e-02, -6.6223e-02, -2.0189e-02,\n",
      "         3.4273e-02, -7.7081e-02, -5.5347e-02,  2.6326e-02, -9.5238e-02,\n",
      "         9.7707e-02,  1.6134e-02, -3.1960e-02, -9.6722e-02,  4.5362e-03,\n",
      "         8.8775e-02, -2.2587e-02, -1.7338e-02, -6.1087e-02, -3.1247e-02,\n",
      "        -2.6211e-02,  8.4526e-02, -9.0652e-02, -2.0481e-02,  6.2251e-02,\n",
      "        -9.9607e-03,  1.4853e-02, -2.6182e-02, -7.2977e-02,  4.1153e-02,\n",
      "        -3.1864e-02, -5.3358e-02, -1.4443e-02,  9.7471e-02,  9.8897e-03,\n",
      "         7.6151e-02, -9.0115e-02,  7.4604e-02,  7.1809e-02, -4.5828e-02,\n",
      "        -7.2876e-02, -1.1085e-02,  7.3066e-02, -6.0975e-02,  9.4830e-02,\n",
      "        -9.1724e-02,  7.5190e-02, -5.7755e-02, -5.9638e-02, -5.2412e-02,\n",
      "        -9.7198e-03, -4.3514e-03,  3.5749e-03,  5.6858e-02, -7.0025e-02,\n",
      "         4.2129e-02,  1.6146e-03, -1.2065e-02, -5.9299e-02, -6.5194e-02,\n",
      "        -2.9018e-02, -9.2239e-02,  2.3148e-02, -7.3490e-02, -5.3450e-02,\n",
      "        -8.7855e-03, -1.7674e-02, -5.7612e-02,  7.8473e-02, -8.3102e-02,\n",
      "         1.8176e-03,  3.6240e-05,  6.3644e-02, -2.8530e-02, -7.8607e-03,\n",
      "         5.8742e-02,  7.0431e-02, -8.5775e-02,  5.9351e-02, -4.9168e-02,\n",
      "        -7.6014e-02, -5.7807e-02,  1.7929e-03, -5.6946e-02,  1.7850e-02,\n",
      "        -9.3800e-03,  1.2795e-02, -9.4144e-02,  5.8569e-02,  1.1657e-02,\n",
      "        -5.2172e-02, -9.1506e-02, -4.4242e-02,  2.0806e-02, -6.3157e-02,\n",
      "        -2.3171e-02, -5.0954e-02, -5.8216e-03, -5.7702e-02, -9.9539e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0395,  0.0264, -0.0608,  ..., -0.0101,  0.0475,  0.0396],\n",
      "        [ 0.0231,  0.0403, -0.0509,  ...,  0.0482,  0.0298,  0.0107],\n",
      "        [ 0.0691,  0.0086, -0.0491,  ...,  0.0474, -0.0037,  0.0166],\n",
      "        ...,\n",
      "        [-0.0698, -0.0016,  0.0282,  ...,  0.0556, -0.0699,  0.0189],\n",
      "        [ 0.0659, -0.0242, -0.0060,  ..., -0.0496, -0.0402,  0.0076],\n",
      "        [-0.0254,  0.0154,  0.0213,  ...,  0.0442,  0.0525, -0.0580]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0660,  0.0601, -0.0511, -0.0254, -0.0204, -0.0295,  0.0017,  0.0110,\n",
      "        -0.0221, -0.0377], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0395,  0.0264, -0.0608,  ..., -0.0101,  0.0475,  0.0396],\n",
      "        [ 0.0231,  0.0403, -0.0509,  ...,  0.0482,  0.0298,  0.0107],\n",
      "        [ 0.0691,  0.0086, -0.0491,  ...,  0.0474, -0.0037,  0.0166],\n",
      "        ...,\n",
      "        [-0.0698, -0.0016,  0.0282,  ...,  0.0556, -0.0699,  0.0189],\n",
      "        [ 0.0659, -0.0242, -0.0060,  ..., -0.0496, -0.0402,  0.0076],\n",
      "        [-0.0254,  0.0154,  0.0213,  ...,  0.0442,  0.0525, -0.0580]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0660,  0.0601, -0.0511, -0.0254, -0.0204, -0.0295,  0.0017,  0.0110,\n",
      "        -0.0221, -0.0377], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5c732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
